{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Trip counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_tripCount_daily','bern_2019_tripCount_hourly',\n",
    "              'geneva_2019_tripCount_daily','geneva_2019_tripCount_hourly',\n",
    "              'geneva_2020_tripCount_daily','geneva_2020_tripCount_hourly',\n",
    "              'lausanne_2019_tripCount_daily','lausanne_2019_tripCount_hourly',\n",
    "              'lausanne_2020_tripCount_daily','lausanne_2020_tripCount_hourly',\n",
    "              'zurich_2019_tripCount_daily','zurich_2019_tripCount_hourly',\n",
    "              'zurich_2020_tripCount_daily','zurich_2020_tripCount_hourly']\n",
    "columns = ['date','total','transport_train','transport_road','transport_highway','commute','non_commute']\n",
    "df_names = ['df_total','df_incoming','df_outto','df_within','df_passing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # separate trip locational types and append date to each\n",
    "    df_total = df.iloc[:,1:7]\n",
    "    df_total = pd.concat([df['Date'],df_total],axis=1)\n",
    "\n",
    "    df_incoming = df.iloc[:,7:13]\n",
    "    df_incoming = pd.concat([df['Date'],df_incoming],axis=1)\n",
    "\n",
    "    df_outto = df.iloc[:,13:19]\n",
    "    df_outto = pd.concat([df['Date'],df_outto],axis=1)\n",
    "\n",
    "    df_within = df.iloc[:,19:25]\n",
    "    df_within = pd.concat([df['Date'],df_within],axis=1)\n",
    "\n",
    "    df_passing = df.iloc[:,25:]\n",
    "    df_passing = pd.concat([df['Date'],df_passing],axis=1)\n",
    "    \n",
    "    # rename columns\n",
    "    df_total.columns = columns\n",
    "    df_incoming.columns = columns\n",
    "    df_outto.columns = columns\n",
    "    df_within.columns = columns\n",
    "    df_passing.columns = columns\n",
    "    \n",
    "    # delete title rows\n",
    "    df_total = df_total.drop([0,1]).reset_index(drop=True)\n",
    "    df_incoming = df_incoming.drop([0,1]).reset_index(drop=True)\n",
    "    df_outto = df_outto.drop([0,1]).reset_index(drop=True)\n",
    "    df_within = df_within.drop([0,1]).reset_index(drop=True)\n",
    "    df_passing = df_passing.drop([0,1]).reset_index(drop=True)\n",
    "    \n",
    "    # combine dfs into dict\n",
    "    df_dict = dict(zip(df_names,[df_total, df_incoming, df_outto, df_within, df_passing]))\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df_dict,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_demographics',\n",
    "             'geneva_2019_demographics','geneva_2020_demographics',\n",
    "             'lausanne_2019_demographics','lausanne_2020_demographics',\n",
    "             'zurich_2019_demographics','zurich_2020_demographics']\n",
    "df_names = ['df_gender','df_age','df_nationality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # sort gender \n",
    "    df_gender = df.iloc[:2,:2]\n",
    "    df_gender.columns = ['male','female']\n",
    "    df_gender = df_gender.drop([0])\n",
    "    \n",
    "    # sort age\n",
    "    df_age = df.iloc[:2,2:]\n",
    "    df_age.columns = ['<20','20-39','40-64','65+']\n",
    "    df_age = df_age.drop([0])\n",
    "    \n",
    "    # sort nationality\n",
    "    df_nationality = df.iloc[5:]\n",
    "    df_nationality = df_nationality.drop(columns=['Age','Unnamed: 3','Unnamed: 4','Unnamed: 5'])\n",
    "    df_nationality.columns = ['nationality','ratio']\n",
    "    df_nationality = df_nationality.reset_index(drop=True)\n",
    "    \n",
    "    # combine dfs into dict\n",
    "    df_dict = dict(zip(df_names,[df_gender,df_age, df_nationality]))\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df_dict,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Origins - Incoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_incomingFrom_origin',\n",
    "             'geneva_2019_incomingFrom_origin','geneva_2020_incomingFrom_origin',\n",
    "             'lausanne_2019_incomingFrom_origin','lausanne_2020_incomingFrom_origin',\n",
    "             'zurich_2019_incomingFrom_origin','zurich_2020_incomingFrom_origin']\n",
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # separate levels of regions\n",
    "    df_postcode = df.iloc[:,:3]\n",
    "    df_postcode = df_postcode.dropna(how='all')\n",
    "    df_municipality = df.iloc[:,3:6]\n",
    "    df_municipality = df_municipality.dropna(how='all')\n",
    "    df_district = df.iloc[:,6:9]\n",
    "    df_district = df_district.dropna(how='all')\n",
    "    df_canton = df.iloc[:,9:]\n",
    "    df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "    # sort columns\n",
    "    df_postcode.columns = columns\n",
    "    df_municipality.columns = columns\n",
    "    df_district.columns = columns\n",
    "    df_canton.columns = columns\n",
    "    \n",
    "    # combine dfs into dict\n",
    "    df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df_dict,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Destinations - Outbounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_fromHereTo_dest',\n",
    "             'geneva_2019_fromHereTo_dest','geneva_2020_fromHereTo_dest',\n",
    "             'lausanne_2019_fromHereTo_dest','lausanne_2020_fromHereTo_dest',\n",
    "             'zurich_2019_fromHereTo_dest','zurich_2020_fromHereTo_dest']\n",
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # separate levels of regions\n",
    "    df_postcode = df.iloc[:,:3]\n",
    "    df_postcode = df_postcode.dropna(how='all')\n",
    "    df_municipality = df.iloc[:,3:6]\n",
    "    df_municipality = df_municipality.dropna(how='all')\n",
    "    df_district = df.iloc[:,6:9]\n",
    "    df_district = df_district.dropna(how='all')\n",
    "    df_canton = df.iloc[:,9:]\n",
    "    df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "    # sort columns\n",
    "    df_postcode.columns = columns\n",
    "    df_municipality.columns = columns\n",
    "    df_district.columns = columns\n",
    "    df_canton.columns = columns\n",
    "    \n",
    "    # combine dfs into dict\n",
    "    df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df_dict,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Origins - PassingThru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_passingThru_origin',\n",
    "             'geneva_2019_passingThru_origin','geneva_2020_passingThru_origin',\n",
    "             'lausanne_2019_passingThru_origin','lausanne_2020_passingThru_origin',\n",
    "             'zurich_2019_passingThru_origin','zurich_2020_passingThru_origin']\n",
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # separate levels of regions\n",
    "    df_postcode = df.iloc[:,:3]\n",
    "    df_postcode = df_postcode.dropna(how='all')\n",
    "    df_municipality = df.iloc[:,3:6]\n",
    "    df_municipality = df_municipality.dropna(how='all')\n",
    "    df_district = df.iloc[:,6:9]\n",
    "    df_district = df_district.dropna(how='all')\n",
    "    df_canton = df.iloc[:,9:]\n",
    "    df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "    # sort columns\n",
    "    df_postcode.columns = columns\n",
    "    df_municipality.columns = columns\n",
    "    df_district.columns = columns\n",
    "    df_canton.columns = columns\n",
    "    \n",
    "    # combine dfs into dict\n",
    "    df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df_dict,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Destinations - PassingThru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_passingThru_dest',\n",
    "             'geneva_2019_passingThru_dest','geneva_2020_passingThru_dest',\n",
    "             'lausanne_2019_passingThru_dest','lausanne_2020_passingThru_dest',\n",
    "             'zurich_2019_passingThru_dest','zurich_2020_passingThru_dest']\n",
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # separate levels of regions\n",
    "    df_postcode = df.iloc[:,:3]\n",
    "    df_postcode = df_postcode.dropna(how='all')\n",
    "    df_municipality = df.iloc[:,3:6]\n",
    "    df_municipality = df_municipality.dropna(how='all')\n",
    "    df_district = df.iloc[:,6:9]\n",
    "    df_district = df_district.dropna(how='all')\n",
    "    df_canton = df.iloc[:,9:]\n",
    "    df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "    # sort columns\n",
    "    df_postcode.columns = columns\n",
    "    df_municipality.columns = columns\n",
    "    df_district.columns = columns\n",
    "    df_canton.columns = columns\n",
    "    \n",
    "    # combine dfs into dict\n",
    "    df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df_dict,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Routes - PassingThru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_passingThru_routes',\n",
    "             'geneva_2019_passingThru_routes','geneva_2020_passingThru_routes',\n",
    "             'lausanne_2019_passingThru_routes','lausanne_2020_passingThru_routes',\n",
    "             'zurich_2019_passingThru_routes','zurich_2020_passingThru_routes']\n",
    "columns = ['id_from','name_from','id_to','name_to','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # separate levels of regions\n",
    "    df_postcode = df.iloc[:,:5]\n",
    "    df_postcode = df_postcode.dropna(how='all')\n",
    "    df_municipality = df.iloc[:,5:10]\n",
    "    df_municipality = df_municipality.dropna(how='all')\n",
    "    df_district = df.iloc[:,10:15]\n",
    "    df_district = df_district.dropna(how='all')\n",
    "    df_canton = df.iloc[:,15:]\n",
    "    df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "    # sort columns\n",
    "    df_postcode.columns = columns\n",
    "    df_municipality.columns = columns\n",
    "    df_district.columns = columns\n",
    "    df_canton.columns = columns\n",
    "    \n",
    "    # combine dfs into dict\n",
    "    df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df_dict,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Dwell time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['bern_2019_dwellTimes',\n",
    "             'geneva_2019_dwellTimes','geneva_2020_dwellTimes',\n",
    "             'lausanne_2019_dwellTimes','lausanne_2020_dwellTimes',\n",
    "             'zurich_2019_dwellTimes','zurich_2020_dwellTimes']\n",
    "columns = ['length_min','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    # import df\n",
    "    df = pd.read_pickle('data_df/' + filename + '.pkl')\n",
    "    \n",
    "    # sort columns\n",
    "    df.columns = columns\n",
    "    df.iloc[-1,0] = '>8h'\n",
    "    \n",
    "    # save dict to pkl\n",
    "    pkl_file = open('dict_'+filename+'.pkl','wb')\n",
    "    pickle.dump(df,pkl_file)\n",
    "    pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daily Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_names = ['df_gender','df_age','df_nationality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/anniezhi/Desktop/HackZurich/Swisscom/data_df_daily'):\n",
    "    if 'demographics' in filename:\n",
    "        # import df\n",
    "        df = pd.read_pickle('data_df_daily/' + filename)\n",
    "    \n",
    "        # sort gender \n",
    "        df_gender = df.iloc[:2,:2]\n",
    "        df_gender.columns = ['male','female']\n",
    "        df_gender = df_gender.drop([0])\n",
    "    \n",
    "        # sort age\n",
    "        df_age = df.iloc[:2,2:]\n",
    "        df_age.columns = ['<20','20-39','40-64','65+']\n",
    "        df_age = df_age.drop([0])\n",
    "    \n",
    "        # sort nationality\n",
    "        df_nationality = df.iloc[5:]\n",
    "        df_nationality = df_nationality.drop(columns=['Age','Unnamed: 3','Unnamed: 4','Unnamed: 5'])\n",
    "        df_nationality.columns = ['nationality','ratio']\n",
    "        df_nationality = df_nationality.reset_index(drop=True)\n",
    "    \n",
    "        # combine dfs into dict\n",
    "        df_dict = dict(zip(df_names,[df_gender,df_age, df_nationality]))\n",
    "    \n",
    "        # save dict to pkl\n",
    "        pkl_file = open('dict_'+filename,'wb')\n",
    "        pickle.dump(df_dict,pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Origins - Incoming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/anniezhi/Desktop/HackZurich/Swisscom/data_df_daily'):\n",
    "    if 'incomingFrom_origin' in filename:\n",
    "        # import df\n",
    "        df = pd.read_pickle('data_df_daily/' + filename)\n",
    "    \n",
    "        # separate levels of regions\n",
    "        df_postcode = df.iloc[:,:3]\n",
    "        df_postcode = df_postcode.dropna(how='all')\n",
    "        df_municipality = df.iloc[:,3:6]\n",
    "        df_municipality = df_municipality.dropna(how='all')\n",
    "        df_district = df.iloc[:,6:9]\n",
    "        df_district = df_district.dropna(how='all')\n",
    "        df_canton = df.iloc[:,9:]\n",
    "        df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "        # sort columns\n",
    "        df_postcode.columns = columns\n",
    "        df_municipality.columns = columns\n",
    "        df_district.columns = columns\n",
    "        df_canton.columns = columns\n",
    "    \n",
    "        # combine dfs into dict\n",
    "        df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "        # save dict to pkl\n",
    "        pkl_file = open('dict_'+filename,'wb')\n",
    "        pickle.dump(df_dict,pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Destinations - Outbounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/anniezhi/Desktop/HackZurich/Swisscom/data_df_daily'):\n",
    "    if 'fromHereTo_dest' in filename:\n",
    "        # import df\n",
    "        df = pd.read_pickle('data_df_daily/' + filename)\n",
    "    \n",
    "        # separate levels of regions\n",
    "        df_postcode = df.iloc[:,:3]\n",
    "        df_postcode = df_postcode.dropna(how='all')\n",
    "        df_municipality = df.iloc[:,3:6]\n",
    "        df_municipality = df_municipality.dropna(how='all')\n",
    "        df_district = df.iloc[:,6:9]\n",
    "        df_district = df_district.dropna(how='all')\n",
    "        df_canton = df.iloc[:,9:]\n",
    "        df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "        # sort columns\n",
    "        df_postcode.columns = columns\n",
    "        df_municipality.columns = columns\n",
    "        df_district.columns = columns\n",
    "        df_canton.columns = columns\n",
    "    \n",
    "        # combine dfs into dict\n",
    "        df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "        # save dict to pkl\n",
    "        pkl_file = open('dict_'+filename,'wb')\n",
    "        pickle.dump(df_dict,pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Origins - PassingThru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/anniezhi/Desktop/HackZurich/Swisscom/data_df_daily'):\n",
    "    if 'passingThru_origin' in filename:\n",
    "        # import df\n",
    "        df = pd.read_pickle('data_df_daily/' + filename)\n",
    "    \n",
    "        # separate levels of regions\n",
    "        df_postcode = df.iloc[:,:3]\n",
    "        df_postcode = df_postcode.dropna(how='all')\n",
    "        df_municipality = df.iloc[:,3:6]\n",
    "        df_municipality = df_municipality.dropna(how='all')\n",
    "        df_district = df.iloc[:,6:9]\n",
    "        df_district = df_district.dropna(how='all')\n",
    "        df_canton = df.iloc[:,9:]\n",
    "        df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "        # sort columns\n",
    "        df_postcode.columns = columns\n",
    "        df_municipality.columns = columns\n",
    "        df_district.columns = columns\n",
    "        df_canton.columns = columns\n",
    "    \n",
    "        # combine dfs into dict\n",
    "        df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "        # save dict to pkl\n",
    "        pkl_file = open('dict_'+filename,'wb')\n",
    "        pickle.dump(df_dict,pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Destinations - PassingThru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id','name','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/anniezhi/Desktop/HackZurich/Swisscom/data_df_daily'):\n",
    "    if 'passingThru_dest' in filename:\n",
    "        # import df\n",
    "        df = pd.read_pickle('data_df_daily/' + filename)\n",
    "    \n",
    "        # separate levels of regions\n",
    "        df_postcode = df.iloc[:,:3]\n",
    "        df_postcode = df_postcode.dropna(how='all')\n",
    "        df_municipality = df.iloc[:,3:6]\n",
    "        df_municipality = df_municipality.dropna(how='all')\n",
    "        df_district = df.iloc[:,6:9]\n",
    "        df_district = df_district.dropna(how='all')\n",
    "        df_canton = df.iloc[:,9:]\n",
    "        df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "        # sort columns\n",
    "        df_postcode.columns = columns\n",
    "        df_municipality.columns = columns\n",
    "        df_district.columns = columns\n",
    "        df_canton.columns = columns\n",
    "    \n",
    "        # combine dfs into dict\n",
    "        df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "        # save dict to pkl\n",
    "        pkl_file = open('dict_'+filename,'wb')\n",
    "        pickle.dump(df_dict,pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Routes - PassingThru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id_from','name_from','id_to','name_to','count']\n",
    "df_names = ['df_postcode','df_municipality','df_district','df_canton']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/anniezhi/Desktop/HackZurich/Swisscom/data_df_daily'):\n",
    "    if 'passingThru_routes' in filename:\n",
    "        # import df\n",
    "        df = pd.read_pickle('data_df_daily/' + filename)\n",
    "    \n",
    "        # separate levels of regions\n",
    "        df_postcode = df.iloc[:,:5]\n",
    "        df_postcode = df_postcode.dropna(how='all')\n",
    "        df_municipality = df.iloc[:,5:10]\n",
    "        df_municipality = df_municipality.dropna(how='all')\n",
    "        df_district = df.iloc[:,10:15]\n",
    "        df_district = df_district.dropna(how='all')\n",
    "        df_canton = df.iloc[:,15:]\n",
    "        df_canton = df_canton.dropna(how='all')\n",
    "    \n",
    "        # sort columns\n",
    "        df_postcode.columns = columns\n",
    "        df_municipality.columns = columns\n",
    "        df_district.columns = columns\n",
    "        df_canton.columns = columns\n",
    "    \n",
    "        # combine dfs into dict\n",
    "        df_dict = dict(zip(df_names,[df_postcode,df_municipality, df_district, df_canton]))\n",
    "    \n",
    "        # save dict to pkl\n",
    "        pkl_file = open('dict_'+filename,'wb')\n",
    "        pickle.dump(df_dict,pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort - Dwell time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['length_min','count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('/Users/anniezhi/Desktop/HackZurich/Swisscom/data_df_daily'):\n",
    "    if 'dwellTimes' in filename:\n",
    "        # import df\n",
    "        df = pd.read_pickle('data_df_daily/' + filename)\n",
    "    \n",
    "        # sort columns\n",
    "        df.columns = columns\n",
    "        df.iloc[-1,0] = '>8h'\n",
    "    \n",
    "        # save dict to pkl\n",
    "        pkl_file = open('dict_'+filename,'wb')\n",
    "        pickle.dump(df,pkl_file)\n",
    "        pkl_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
